{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from collections import defaultdict\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image_mask to polygons\n",
    "#code origin: https://michhar.github.io/masks_to_polygons_and_back/\n",
    "\n",
    "def mask_to_polygons(mask, epsilon=10., min_area=10.):\n",
    "    \"\"\"Convert a mask ndarray (binarized image) to Multipolygons\"\"\"\n",
    "       \n",
    "    # first, find contours with cv2: it's much faster than shapely\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "    if not contours:\n",
    "        return MultiPolygon()\n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(contours[idx])\n",
    "    # create actual polygons filtering by area (removes artifacts)\n",
    "    all_polygons = []\n",
    "    for idx, cnt in enumerate(contours):\n",
    "        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n",
    "            assert cnt.shape[1] == 1\n",
    "            poly = Polygon(\n",
    "                shell=cnt[:, 0, :],\n",
    "                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n",
    "                       if cv2.contourArea(c) >= min_area])\n",
    "            all_polygons.append(poly)\n",
    "    all_polygons = MultiPolygon(all_polygons)\n",
    "\n",
    "    return all_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load reference_list\n",
    "\n",
    "sample_path = \"./demo_brain/\"\n",
    "\n",
    "rsplist = pd.read_csv (sample_path + \"reference_list.csv\", index_col = 0)\n",
    "rsplist[\"mask_number\"]= [1320-int(a) for a in rsplist[\"0\"].tolist()]\n",
    "rsplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate cfos_spot_csv/slice from Imaris spot_position.csv \n",
    "cfos_spot = pd.read_csv (sample_path + \"position_Detailed.csv\")\n",
    "\n",
    "cfos_spot_folder = sample_path + \"cfos_spot\"\n",
    "if not os.path.exists(cfos_spot_folder):\n",
    "    os.makedirs(cfos_spot_folder)\n",
    "\n",
    "for b in np.arange (len(rsplist))+1:\n",
    "    spot =[]\n",
    "    for indexc, varac in cfos_spot [cfos_spot[\"Time\"]==b].iterrows():\n",
    "        #\"/1.76\" means convert coordinate from 1.76 micrometer/pixel to 1 pixel/pixel\n",
    "        point =(cfos_spot[\"Position X\"][indexc]/1.76, cfos_spot[\"Position Y\"][indexc]/1.76) \n",
    "        spot.append (point)\n",
    "    pd.DataFrame (spot, columns = [\"0\", \"1\"]).to_csv (cfos_spot_folder + \"/spot\"+str (b)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch analysis of oChIEF_b and C-FOS signals\n",
    "\n",
    "#Brain region list for analysis\n",
    "structure_list = pd.read_csv(\"./CCFv3/structuretree/structure_list_paper.csv\", index_col = 0)\n",
    "\n",
    "#subset brain regions\n",
    "DMN_list = [\"ACAd\", \"ACAv\", \"PL\", \"ILA\", \"ORBl\", \"ORBm\", \"ORBvl\", \n",
    "            \"VISa\", \"VISam\", \"RSPagl\", \"RSPd\", \"RSPv\", \n",
    "            \"SSp-tr\", \"SSp-ll\", \"MOs\"]\n",
    "\n",
    "structure_list_idx = structure_list[structure_list[\"LABEL\"].isin(DMN_list)].IDX.tolist()\n",
    "\n",
    "for c in structure_list_idx:\n",
    "    \n",
    "    structrue_index = structure_list[structure_list[\"IDX\"]==c].index.values[0]\n",
    "    slice_number = []    \n",
    "    cfos_spot_L = []\n",
    "    cfos_spot_R = []\n",
    "    spot_L_size = []\n",
    "    spot_R_size =[]\n",
    "    area_all =[]\n",
    "    cfos_L_densitylist =[]\n",
    "    cfos_R_densitylist = []    \n",
    "    oChIEF_L_binary_list = []\n",
    "    oChIEF_R_binary_list = []\n",
    "    \n",
    "    structure_path = sample_path +\"quantification/\"+str(structure_list.loc[structrue_index, \"LABEL\"])\n",
    "    \n",
    "    if not os.path.exists(structure_path):\n",
    "        os.makedirs(structure_path)\n",
    "\n",
    "\n",
    "    for d in rsplist[\"mask_number\"]:\n",
    "        \n",
    "        if  d in json.loads(structure_list[\"section_number\"][structrue_index]):\n",
    "            \n",
    "            slice_n = rsplist[\"mask_number\"].to_list().index(d)+1\n",
    "            slice_number.append (slice_n)\n",
    "            \n",
    "            #open matched regional mask within our experiment slices\n",
    "            #regional masks can be obtained from Allen Brain Reference Space\n",
    "            #https://allensdk.readthedocs.io/en/latest/_static/examples/nb/reference_space.html\n",
    "            mask=pd.read_csv (\"./CCFv3/mask/mask\"+str(structure_list[\"IDX\"][structrue_index])+\"/mask\"+str(d)+\".csv\", header = 0, index_col = 0).values\n",
    "        \n",
    "            # enlarge to highcontent image scale (1140 x 800 pixels to 6480 x 4547 pixels)\n",
    "            highcontent_mask = rescale (mask, 5.6842105263, anti_aliasing=False)\n",
    "            \n",
    "            #convert to 8 bit binary image mask\n",
    "            highcontent_mask_bw =(highcontent_mask>np.mean (highcontent_mask)).astype(\"uint8\")\n",
    "        \n",
    "\n",
    "            # convert 8 bit binary image mask to shapely multipolygon \n",
    "            mask_poly = mask_to_polygons(highcontent_mask_bw, min_area = 10)\n",
    "\n",
    "            #write multipolygon into geoseries\n",
    "            mask_geopd = geopandas.GeoSeries([mask_poly])\n",
    "        \n",
    "            #open matched cfos spot csv\n",
    "            spot = pd.read_csv (sample_path +\"cfos_spot/spot\"+str(rsplist[\"mask_number\"].to_list().index(d)+1)+\".csv\", header = 0, index_col = 0)     \n",
    "            spotL = spot[spot[\"0\"]<3240]\n",
    "            spotR = spot[spot[\"0\"]>=3240]\n",
    "\n",
    "            #convert cfos spot DataFrame to GeoDataFrame containing shapely points\n",
    "            spotL_geopd = geopandas.GeoDataFrame (spotL, geometry = geopandas.points_from_xy(spotL[\"0\"], spotL[\"1\"])) \n",
    "            spotR_geopd = geopandas.GeoDataFrame (spotR, geometry = geopandas.points_from_xy(spotR[\"0\"], spotR[\"1\"]))\n",
    "            \n",
    "            #calculate cfos density within regional mask (unit: #/ square minimeter)\n",
    "            cfosL_density = float(len(spotL_geopd[spotL_geopd.within(mask_poly.buffer(0))])/mask_geopd.area)/(1.76**2)*2000000\n",
    "            cfos_L_densitylist.append(cfosL_density)       \n",
    "            cfosL_spot = np.transpose([spotL_geopd[spotL_geopd.within(mask_poly.buffer(0))][\"0\"].tolist(), \n",
    "                          spotL_geopd[spotL_geopd.within(mask_poly.buffer(0))][\"1\"].tolist(),\n",
    "                          (np.zeros (len (spotL_geopd[spotL_geopd.within(mask_poly.buffer(0))][\"0\"]))+slice_n).tolist()]).tolist()        \n",
    "            cfos_spot_L+=cfosL_spot\n",
    "            spot_L_size.append (len(spotL_geopd[spotL_geopd.within(mask_poly.buffer(0))]))\n",
    "        \n",
    "            cfosR_density = float(len(spotR_geopd[spotR_geopd.within(mask_poly.buffer(0))])/mask_geopd.area)/(1.76**2)*2000000\n",
    "            cfos_R_densitylist.append(cfosR_density)\n",
    "            cfosR_spot = np.transpose([spotR_geopd[spotR_geopd.within(mask_poly.buffer(0))][\"0\"].tolist(), \n",
    "                          spotR_geopd[spotR_geopd.within(mask_poly.buffer(0))][\"1\"].tolist(),\n",
    "                          (np.zeros (len (spotR_geopd[spotR_geopd.within(mask_poly.buffer(0))][\"0\"]))+slice_n).tolist()]).tolist()\n",
    "            cfos_spot_R+=cfosR_spot\n",
    "            spot_R_size.append (len(spotR_geopd[spotR_geopd.within(mask_poly.buffer(0))]))\n",
    "            \n",
    "            area_all.append (float(mask_geopd.area))\n",
    "            \n",
    "            #open oChIEF binary image size: 6480 x 4547 pixels\n",
    "            binary_img = imread(sample_path + \"oChIEF_T_b/oChIEF_T_b\"+\"%04d\"%(rsplist[\"mask_number\"].to_list().index(d))+\".png\")/255\n",
    "            \n",
    "            #only show mask region oChIEF signals\n",
    "            binary_imgmask = np.where (highcontent_mask>np.mean(highcontent_mask), binary_img, 0)\n",
    "            L_b = binary_imgmask[:, :3240]\n",
    "            R_b = binary_imgmask[:,3240:]\n",
    "            \n",
    "            #calculate regional oChIEF mean pixels\n",
    "            mean_L_b = (np.mean (L_b))\n",
    "            oChIEF_L_binary_list.append(mean_L_b)\n",
    "                   \n",
    "            mean_R_b = (np.mean (R_b))\n",
    "            oChIEF_R_binary_list.append(mean_R_b)\n",
    "            \n",
    "    pd.DataFrame (list(zip(slice_number, cfos_L_densitylist, cfos_R_densitylist)),columns=[\"slice_number\",\"cfos_L_density\", \"cfos_R_density\"]).to_csv (structure_path +\"/cfos_density.csv\")\n",
    "    pd.DataFrame ({\"slice_number\":slice_number, \"cfos_L_spot_number\": spot_L_size, \"cfos_R_spot_number\": spot_R_size, \"structure_area (pixels)\": area_all}).to_csv (structure_path +\"/cfos_density_raw.csv\")\n",
    "    pd.DataFrame (list(zip(slice_number, oChIEF_L_binary_list, oChIEF_R_binary_list)),columns=[\"slice_number\",\"oChIEF_L_b_mean\", \"oChIEF_R_b_mean\"]).to_csv (structure_path +\"/oChIEF_meanint_b.csv\")\n",
    "    pd.DataFrame (cfos_spot_L, columns = [\"x(pixels)\",\"y(pixels)\",\"z(pixels)\"]).to_csv (structure_path +\"/cfos_L_spot_location.csv\")\n",
    "    pd.DataFrame (cfos_spot_R, columns = [\"x(pixels)\",\"y(pixels)\",\"z(pixels)\"]).to_csv (structure_path +\"/cfos_R_spot_location.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of oChIEF_data_binarizedimages\n",
    "quantification_path = sample_path +\"quantification/\"\n",
    "\n",
    "oChIEF_L_summary = pd.DataFrame (index = DMN_list, columns = np.arange (len(rsplist))+1)\n",
    "oChIEF_R_summary = pd.DataFrame (index = DMN_list, columns = np.arange (len(rsplist))+1)\n",
    "\n",
    "for f in DMN_list:\n",
    "    for root, dirs, files in os.walk (quantification_path +f):\n",
    "        for filef in files:\n",
    "            if filef.endswith (\"oChIEF_meanint_b.csv\"):\n",
    "                oChIEF = pd.read_csv (os.path.join(root, filef), index_col = 0)\n",
    "                for indexe, varae in oChIEF.iterrows():\n",
    "                    oChIEF_L_summary.at [f, oChIEF.slice_number[indexe]]=oChIEF.oChIEF_L_b_mean[indexe]\n",
    "                    oChIEF_R_summary.at [f, oChIEF.slice_number[indexe]]=oChIEF.oChIEF_R_b_mean[indexe]\n",
    "                    \n",
    "oChIEF_L_summary.to_csv (sample_path + \"oChIEF_L_summary_b.csv\")\n",
    "oChIEF_R_summary.to_csv (sample_path +\"oChIEF_R_summary_b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of cfos_density_data\n",
    "quantification_path = sample_path +\"quantification/\"\n",
    "\n",
    "cfos_L_summary = pd.DataFrame (index = DMN_list, columns = np.arange (len(rsplist))+1)\n",
    "cfos_R_summary = pd.DataFrame (index = DMN_list, columns = np.arange (len(rsplist))+1)\n",
    "\n",
    "for f in DMN_list:\n",
    "    for root, dirs, files in os.walk (quantification_path +f):\n",
    "            for file in files:\n",
    "                if file.endswith (\"cfos_density.csv\"):\n",
    "                    cfos = pd.read_csv (os.path.join(root, file), index_col = 0)\n",
    "                    for indexa, varaa in cfos.iterrows():\n",
    "                        cfos_L_summary.at [f, cfos.slice_number[indexa]]=cfos.cfos_L_density[indexa]\n",
    "                        cfos_R_summary.at [f, cfos.slice_number[indexa]]=cfos.cfos_R_density[indexa]\n",
    "cfos_L_summary.to_csv (sample_path + \"cfos_L_summary.csv\")\n",
    "cfos_R_summary.to_csv (sample_path + \"cfos_R_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of cfos_number_data\n",
    "quantification_path = sample_path +\"quantification/\"\n",
    "\n",
    "cfos_L_summary = pd.DataFrame (index = DMN_list, columns = np.arange (len(rsplist))+1)\n",
    "cfos_R_summary = pd.DataFrame (index = DMN_list, columns = np.arange (len(rsplist))+1)\n",
    "\n",
    "for f in DMN_list:\n",
    "    for root, dirs, files in os.walk (quantification_path +f):\n",
    "            for file in files:\n",
    "                if file.endswith (\"cfos_density_raw.csv\"):\n",
    "                    cfos = pd.read_csv (os.path.join(root, file), index_col = 0)\n",
    "                    for indexa, varaa in cfos.iterrows():\n",
    "                        cfos_L_summary.at [f, cfos.slice_number[indexa]]=cfos.cfos_L_spot_number[indexa]\n",
    "                        cfos_R_summary.at [f, cfos.slice_number[indexa]]=cfos.cfos_R_spot_number[indexa]\n",
    "cfos_L_summary.to_csv (sample_path + \"cfos_L_num_summary.csv\")\n",
    "cfos_R_summary.to_csv (sample_path + \"cfos_R_num_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of area_data\n",
    "quantification_path = sample_path +\"quantification/\"\n",
    "\n",
    "area_summary = pd.DataFrame (index = DMN_list, columns = np.arange (len(rsplist))+1)\n",
    "\n",
    "for f in DMN_list:\n",
    "    for root, dirs, files in os.walk (quantification_path +f):\n",
    "            for file in files:\n",
    "                if file.endswith (\"cfos_density_raw.csv\"):\n",
    "                    area = pd.read_csv (os.path.join(root, file), index_col = 0)\n",
    "                    for indexa, varaa in area.iterrows():\n",
    "                        area_summary.at [f, area.slice_number[indexa]]=(area[\"structure_area (pixels)\"][indexa])/(2*(1.76**2))\n",
    "area_summary.to_csv (sample_path + \"area_summary.csv\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put the quantified data to folder \"./quantification/genotype/st_pattern/Sample_folder\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "33581cfade5be15d2a6d9b9079fe4b3b8c59e6a970b8759037f9914141a1f7cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
